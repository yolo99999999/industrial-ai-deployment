# **3. yolov5_demo.py**
"""
yolov5_demo.py - YOLOv5ç›®æ ‡æ£€æµ‹ç¤ºä¾‹
åŒ…å«: YOLOv5æ¨¡å‹åŠ è½½ã€æ¨ç†ã€ç»“æœå¯è§†åŒ–
"""

import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import time
import warnings
warnings.filterwarnings('ignore')


class YOLOv5Demo:
    """
    YOLOv5ç›®æ ‡æ£€æµ‹æ¼”ç¤ºç±»
    """

    def __init__(self, model_name='yolov5s', device=None):
        """
        åˆå§‹åŒ–YOLOv5æ¨¡å‹

        Args:
            model_name: æ¨¡å‹åç§° ('yolov5n', 'yolov5s', 'yolov5m',
                                'yolov5l', 'yolov5x')
            device: è®¡ç®—è®¾å¤‡ ('cpu', 'cuda', 'cuda:0')
        """
        print("=" * 60)
        print("YOLOv5ç›®æ ‡æ£€æµ‹æ¼”ç¤º")
        print("=" * 60)

        # è®¾ç½®è®¾å¤‡
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device

        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        if self.device == 'cuda':
            print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")

        # åŠ è½½æ¨¡å‹
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}...")
        self.model = self.load_model(model_name)

        # COCOæ•°æ®é›†ç±»åˆ«æ ‡ç­¾ (YOLOv5é»˜è®¤ä½¿ç”¨COCO)
        self.class_names = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
            'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
            'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
            'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
            'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',
            'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
            'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',
            'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv',
            'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',
            'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',
            'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ]

        # é¢œè‰²æ˜ å°„ (ä¸åŒç±»åˆ«ä¸åŒé¢œè‰²)
        self.colors = self.generate_colors(len(self.class_names))

        print(" âœ… æ¨¡å‹åŠ è½½å®Œæˆ!")
        print(f"   ç±»åˆ«æ•°é‡: {len(self.class_names)}")
        print(f"   æ¨¡å‹ç»“æ„: {self.model.__class__.__name__}")

    def load_model(self, model_name):
        """
        åŠ è½½YOLOv5æ¨¡å‹

        æ³¨æ„:è¿™é‡Œä½¿ç”¨torch.hubåŠ è½½,éœ€è¦ç½‘ç»œè¿æ¥
        å¦‚æœç½‘ç»œé—®é¢˜,å¯ä»¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶
        """
        try:
            # æ–¹æ³•1: ä½¿ç”¨torch.hubä»å®˜æ–¹ä»“åº“åŠ è½½
            model = torch.hub.load('ultralytics/yolov5', model_name,
                                   pretrained=True)
            model.to(self.device)
            model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

            # æ‰“å°æ¨¡å‹ä¿¡æ¯
            print(f"   âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_name}")

            return model

        except Exception as e:
            print(f"   âš  æ— æ³•ä»hubåŠ è½½æ¨¡å‹: {e}")
            print("   å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å¼...")

            # æ–¹æ³•2: ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
            # è¿™é‡Œå¯ä»¥æ·»åŠ æœ¬åœ°æ¨¡å‹åŠ è½½é€»è¾‘
            raise RuntimeError("è¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸,æˆ–æä¾›æœ¬åœ°æ¨¡å‹è·¯å¾„")

    def generate_colors(self, n):
        """ç”ŸæˆNç§ä¸åŒçš„é¢œè‰²"""
        np.random.seed(42)
        colors = np.random.randint(0, 255, size=(n, 3), dtype=np.uint8)
        return colors

    def preprocess_image(self, image_path):
        """
        é¢„å¤„ç†å›¾åƒ

        Args:
            image_path: å›¾åƒè·¯å¾„æˆ–URL

        Returns:
            é¢„å¤„ç†åçš„å›¾åƒå¼ é‡
        """
        # è¯»å–å›¾åƒ
        if isinstance(image_path, str) and image_path.startswith('http'):
            # ä»URLåŠ è½½
            import requests
            from PIL import Image
            import io

            response = requests.get(image_path)
            img = Image.open(io.BytesIO(response.content))
            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        else:
            # ä»æ–‡ä»¶åŠ è½½
            img = cv2.imread(image_path)

        if img is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")

        # ä¿å­˜åŸå§‹å›¾åƒç”¨äºæ˜¾ç¤º
        self.original_img = img.copy()

        # è½¬æ¢é¢œè‰²ç©ºé—´
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        return img_rgb

    def detect(self, image_path, confidence_threshold=0.5):
        """
        æ‰§è¡Œç›®æ ‡æ£€æµ‹

        Args:
            image_path: å›¾åƒè·¯å¾„æˆ–URL
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            æ£€æµ‹ç»“æœ (bounding boxes, confidences, class_ids)
        """
        print(f"\næ­£åœ¨æ£€æµ‹å›¾åƒ: {image_path}")
        print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold}")

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        try:
            # é¢„å¤„ç†å›¾åƒ
            img_rgb = self.preprocess_image(image_path)

            # ä½¿ç”¨YOLOv5è¿›è¡Œæ¨ç†
            results = self.model(img_rgb)

            # è§£æç»“æœ
            detections = results.pandas().xyxy[0]  # è·å–æ£€æµ‹ç»“æœ

            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
            detections = detections[
                detections['confidence'] > confidence_threshold]

            # è®¡ç®—æ¨ç†æ—¶é—´
            inference_time = time.time() - start_time

            print("âœ… æ£€æµ‹å®Œæˆ!")
            print(f"   æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
            print(f"   æ¨ç†æ—¶é—´: {inference_time:.3f} ç§’")
            print(f"   å¸§ç‡: {1/inference_time:.1f} FPS")

            # æå–æ£€æµ‹æ¡†ä¿¡æ¯
            boxes = []
            confidences = []
            class_ids = []

            for _, detection in detections.iterrows():
                xmin = int(detection['xmin'])
                ymin = int(detection['ymin'])
                xmax = int(detection['xmax'])
                ymax = int(detection['ymax'])
                conf = detection['confidence']
                class_id = int(detection['class'])

                boxes.append([xmin, ymin, xmax, ymax])
                confidences.append(conf)
                class_ids.append(class_id)

            return boxes, confidences, class_ids

        except Exception as e:
            print(f"âŒ æ£€æµ‹å¤±è´¥: {e}")
            return [], [], []

    def draw_detections(self, boxes, confidences, class_ids):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ

        Args:
            boxes: è¾¹ç•Œæ¡†åˆ—è¡¨
            confidences: ç½®ä¿¡åº¦åˆ—è¡¨
            class_ids: ç±»åˆ«IDåˆ—è¡¨

        Returns:
            ç»˜åˆ¶åçš„å›¾åƒ
        """
        img = self.original_img.copy()

        for box, conf, class_id in zip(boxes, confidences, class_ids):
            xmin, ymin, xmax, ymax = box

            # è·å–ç±»åˆ«åç§°å’Œé¢œè‰²
            class_name = self.class_names[class_id]
            color = self.colors[class_id].tolist()

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color, 2)

            # åˆ›å»ºæ ‡ç­¾æ–‡æœ¬
            label = f"{class_name}: {conf:.2f}"

            # è®¡ç®—æ ‡ç­¾æ–‡æœ¬å¤§å°
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )

            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            cv2.rectangle(
                img,
                (xmin, ymin - text_height - baseline - 5),
                (xmin + text_width, ymin),
                color,
                -1  # å¡«å……
            )

            # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
            cv2.putText(
                img,
                label,
                (xmin, ymin - baseline - 2),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),  # ç™½è‰²æ–‡å­—
                1
            )

        return img

    def visualize_results(self, img_with_boxes, boxes, confidences, class_ids):
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ

        Args:
            img_with_boxes: ç»˜åˆ¶äº†æ£€æµ‹æ¡†çš„å›¾åƒ
            boxes: è¾¹ç•Œæ¡†åˆ—è¡¨
            confidences: ç½®ä¿¡åº¦åˆ—è¡¨
            class_ids: ç±»åˆ«IDåˆ—è¡¨
        """
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(1, 2, figsize=(15, 7))

        # å­å›¾1: åŸå§‹å›¾åƒ
        axes[0].imshow(cv2.cvtColor(self.original_img, cv2.COLOR_BGR2RGB))
        axes[0].set_title('åŸå§‹å›¾åƒ')
        axes[0].axis('off')

        # å­å›¾2: æ£€æµ‹ç»“æœ
        axes[1].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axes[1].set_title(f'æ£€æµ‹ç»“æœ ({len(boxes)}ä¸ªç›®æ ‡)')
        axes[1].axis('off')

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if boxes:
            stats_text = "æ£€æµ‹ç»Ÿè®¡:\n"
            stats_text += f"â€¢ ç›®æ ‡æ•°é‡: {len(boxes)}\n"

            # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ•°é‡
            class_counts = {}
            for class_id in class_ids:
                class_name = self.class_names[class_id]
                class_counts[class_name] = class_counts.get(class_name, 0) + 1

            stats_text += "â€¢ ç±»åˆ«åˆ†å¸ƒ:\n"
            for class_name, count in class_counts.items():
                stats_text += f"  - {class_name}: {count}ä¸ª\n"

            stats_text += f"â€¢ å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.3f}"

            # åœ¨å›¾åƒå³ä¾§æ·»åŠ æ–‡æœ¬
            plt.figtext(0.75, 0.5, stats_text, fontsize=10,
                        bbox=dict(boxstyle="round,pad=0.3",
                                  facecolor="lightgray"))

        plt.tight_layout()
        plt.savefig('yolov5_detection_results.png',
                    dpi=150, bbox_inches='tight')
        print("âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜ä¸º: yolov5_detection_results.png")
        plt.show()

    def test_with_sample_image(self):
        """ä½¿ç”¨ç¤ºä¾‹å›¾åƒè¿›è¡Œæµ‹è¯•"""
        print("\n" + "=" * 60)
        print("ä½¿ç”¨ç¤ºä¾‹å›¾åƒæµ‹è¯•")
        print("=" * 60)

        # ç¤ºä¾‹å›¾åƒURL (æ¥è‡ªç½‘ç»œ)
        sample_urls = [
            "https://ultralytics.com/images/zidane.jpg",
            "https://ultralytics.com/images/bus.jpg",
        ]

        for i, url in enumerate(sample_urls):
            print(f"\næµ‹è¯•å›¾åƒ {i+1}/{len(sample_urls)}: {url}")

            try:
                # æ‰§è¡Œæ£€æµ‹
                boxes, confidences, class_ids = self.detect(
                    url,
                    confidence_threshold=0.25
                )

                if boxes:
                    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                    img_with_boxes = self.draw_detections(
                                        boxes, confidences, class_ids)

                    # å¯è§†åŒ–
                    self.visualize_results(img_with_boxes,
                                           boxes, confidences, class_ids)

                    # ä¿å­˜ç»“æœå›¾åƒ
                    output_path = f"yolov5_result_{i+1}.jpg"
                    cv2.imwrite(output_path, img_with_boxes)
                    print(f"âœ… ç»“æœå›¾åƒå·²ä¿å­˜ä¸º: {output_path}")
                else:
                    print("âš  æœªæ£€æµ‹åˆ°ç›®æ ‡")

            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    def test_with_local_image(self, image_path):
        """ä½¿ç”¨æœ¬åœ°å›¾åƒè¿›è¡Œæµ‹è¯•"""
        print("\n" + "=" * 60)
        print("ä½¿ç”¨æœ¬åœ°å›¾åƒæµ‹è¯•")
        print("=" * 60)

        if not Path(image_path).exists():
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            print("è¯·æä¾›æœ¬åœ°å›¾åƒè·¯å¾„æˆ–ä½¿ç”¨ç¤ºä¾‹å›¾åƒ")
            return

        try:
            # æ‰§è¡Œæ£€æµ‹
            boxes, confidences, class_ids = self.detect(
                image_path,
                confidence_threshold=0.25
            )

            if boxes:
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                img_with_boxes = self.draw_detections(boxes,
                                                      confidences, class_ids)

                # å¯è§†åŒ–
                self.visualize_results(img_with_boxes,
                                       boxes, confidences, class_ids)

                # ä¿å­˜ç»“æœå›¾åƒ
                output_path = "yolov5_local_result.jpg"
                cv2.imwrite(output_path, img_with_boxes)
                print(f"âœ… ç»“æœå›¾åƒå·²ä¿å­˜ä¸º: {output_path}")
            else:
                print("âš  æœªæ£€æµ‹åˆ°ç›®æ ‡")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    def benchmark_performance(self):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\n" + "=" * 60)
        print("æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 60)

        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        cv2.imwrite("test_benchmark.jpg", test_img)

        # é¢„çƒ­
        print("é¢„çƒ­æ¨¡å‹...")
        for _ in range(3):
            _ = self.detect("test_benchmark.jpg", confidence_threshold=0.5)

        # æ­£å¼æµ‹è¯•
        n_tests = 10
        print(f"è¿›è¡Œ {n_tests} æ¬¡æ¨ç†æµ‹è¯•...")

        inference_times = []

        for i in range(n_tests):
            start_time = time.time()
            boxes, _, _ = self.detect("test_benchmark.jpg",
                                      confidence_threshold=0.5)
            inference_time = time.time() - start_time
            inference_times.append(inference_time)

            print(f"  æµ‹è¯• {i+1}/{n_tests}: {inference_time:.3f}s, "
                  f"  æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡")

        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        Path("test_benchmark.jpg").unlink(missing_ok=True)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_time = np.mean(inference_times)
        std_time = np.std(inference_times)
        fps = 1 / avg_time

        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.3f} Â± {std_time:.3f} ç§’")
        print(f"  å¹³å‡å¸§ç‡: {fps:.1f} FPS")
        print(f"  æœ€å¿«æ¨ç†: {min(inference_times):.3f} ç§’ "
              f"  ({1/min(inference_times):.1f} FPS)")
        print(f"  æœ€æ…¢æ¨ç†: {max(inference_times):.3f} ç§’ "
              f"  ({1/max(inference_times):.1f} FPS)")

        # å¯è§†åŒ–æ€§èƒ½ç»“æœ
        plt.figure(figsize=(10, 5))

        plt.subplot(1, 2, 1)
        plt.plot(range(1, n_tests + 1), inference_times,
                 'bo-', linewidth=2, markersize=8)
        plt.axhline(y=avg_time, color='r', linestyle='--',
                    label=f'å¹³å‡: {avg_time:.3f}s')
        plt.xlabel('æµ‹è¯•æ¬¡æ•°')
        plt.ylabel('æ¨ç†æ—¶é—´ (ç§’)')
        plt.title('YOLOv5æ¨ç†æ—¶é—´')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.subplot(1, 2, 2)
        fps_values = [1/t for t in inference_times]
        plt.bar(range(1, n_tests + 1), fps_values, color='green', alpha=0.7)
        plt.axhline(y=fps, color='r', linestyle='--',
                    label=f'å¹³å‡: {fps:.1f} FPS')
        plt.xlabel('æµ‹è¯•æ¬¡æ•°')
        plt.ylabel('å¸§ç‡ (FPS)')
        plt.title('YOLOv5æ¨ç†å¸§ç‡')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('yolov5_performance_benchmark.png',
                    dpi=150, bbox_inches='tight')
        print("âœ… æ€§èƒ½å›¾è¡¨å·²ä¿å­˜ä¸º: yolov5_performance_benchmark.png")
        plt.show()


def main():
    """ä¸»å‡½æ•°"""
    print("YOLOv5ç›®æ ‡æ£€æµ‹æ¼”ç¤º")
    print("=" * 60)

    try:
        # 1. åˆå§‹åŒ–YOLOv5æ¨¡å‹
        print("1. åˆå§‹åŒ–æ¨¡å‹...")
        detector = YOLOv5Demo(model_name='yolov5s')

        # 2. æµ‹è¯•é€‰é¡¹
        print("\n2. é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
        print("   1. ä½¿ç”¨ç¤ºä¾‹å›¾åƒæµ‹è¯• (éœ€è¦ç½‘ç»œ)")
        print("   2. ä½¿ç”¨æœ¬åœ°å›¾åƒæµ‹è¯•")
        print("   3. æ€§èƒ½åŸºå‡†æµ‹è¯•")

        choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()

        if choice == '1':
            # ä½¿ç”¨ç¤ºä¾‹å›¾åƒæµ‹è¯•
            detector.test_with_sample_image()

        elif choice == '2':
            # ä½¿ç”¨æœ¬åœ°å›¾åƒæµ‹è¯•
            image_path = input("è¯·è¾“å…¥æœ¬åœ°å›¾åƒè·¯å¾„: ").strip()
            detector.test_with_local_image(image_path)

        elif choice == '3':
            # æ€§èƒ½åŸºå‡†æµ‹è¯•
            detector.benchmark_performance()

        else:
            print("âš  æ— æ•ˆé€‰æ‹©,ä½¿ç”¨ç¤ºä¾‹å›¾åƒæµ‹è¯•")
            detector.test_with_sample_image()

        print("\n" + "=" * 60)
        print("ğŸ‰ YOLOv5æ¼”ç¤ºå®Œæˆ!")
        print("=" * 60)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print("\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
        print("   æ¨¡å‹: yolov5s")
        print("   å‚æ•°é‡: çº¦7ç™¾ä¸‡")
        print("   è¾“å…¥å°ºå¯¸: 640x640")
        print("   ç±»åˆ«æ•°: 80 (COCOæ•°æ®é›†)")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

        print("\nğŸ’¡ æ•…éšœæ’é™¤å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥ (éœ€è¦ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹)")
        print("   2. å®‰è£…ä¾èµ–: pip install opencv-python matplotlib")
        print("   3. ç¡®ä¿PyTorchå·²æ­£ç¡®å®‰è£…")
        print("   4. å¦‚ä»æœ‰é—®é¢˜,å¯å°è¯•å…¶ä»–æ¨¡å‹æˆ–æœ¬åœ°æ¨¡å‹")


if __name__ == "__main__":
    main()
